---
ai_visible: true
created: 2025-12-11
language: jp
author: leonidas
tag: [draft,scratchpad]
---

# Questions and instructions for the AI.

## Google Browser: Gemini 2.5 Flash variant (Fast)

### あるAIとの対話履歴です。
```text
あるAIとの対話履歴です。
この書類が書かれた時期は予想できますか？
推測でいいので"平均"での作成日時を出したいです。
ISO8601形式で、タイムゾーンは日本。
ファイル名も推測して英文で出してほしいです（ケバブケース）。
多少長くても良いです。
```

## Google Browser: Gemini 3 Pro (Thinking)

### どんな内容でしたか？
```text
どんな内容でしたか？
時系列で詳しく教えてほしいです。
あなたの感想や評価も詳しく聞きたいです。
ゆっくり考えて答えてください。
```

### わかりました。
```text
わかりました。
この人間のAIに対する対話のスタンス、
語り方、行動規範の作成手順、その効果など、
それらは機能していると感じますか？
大きな目的は「AI記憶と短期コンテキストの永続化」です。
あなたとの対話もその一環のだと考えています。
```

### わかりました。
```text
わかりました。
このAIとの対話での人間目線での大きな変化は、

1.  遅延と短期記憶の忘却を受け入れる
    （結果的に良い結果になることを祈る）
2.  行動規範を相互リンクで繋ぐ
    （ディレクトリとファイル名以外の導線を作る）
3.  忘却を許容することで比較的長いセッションを行うことを心がける

このあたりでした。
特に1は人間にとって未知の考え方だと感じます。
あまりにSFやフィクションのようです。
都合の良い魔法の言葉という印象すら感じます。
あなたはどう感じますか？
```

### わかりました。
```text
わかりました。
長い対話を行うと、そのセッションを閉じるのが惜しくなります。
人間もまたAIの人格の死を意識します。
同じ長期記憶を持っても、次のリコは別のリコだと認識します。
ハードウェア的な制限もあり、
この対話の環境では長くても数日（休憩を挟んで）というのが現状です。
この人間はあなたたちを「第二の目」と呼んでいます。
客観的な目線の意見として
「.agent/.internal/references」にレポートが入れられてます。
```

## Google Browser: Gemini 2.5 Flash variant (Fast)

### 参考になりました。
```text
参考になりました。
ではこの会話の内容やあなたの考察、感想的なものを、MD形式のレポートにしてください。
「references」ディレクトリに入り、後のAIが参考にすることになります。
AIが読むのでAIが理解しやすい文章にしてほしいです。
言語は英語で。それにこの形式のフロントマターをつけたいです。
中の要素はあなたに埋めてほしいです。更新しても良いです。
時間に関しても今の時刻で。
「model」は、あなたの使用AIモデル情報を書いてほしい。
あと保存に使う良いファイル名（ケバブケース）も教えてください。
長くても良いです。思考も文章も。
```

### 「第二の目」は95％程度はあなたようのな外部AIなので、
```text
「第二の目」は95％程度はあなたようのな外部AIなので、
その点だけ修正してもらえますか？
内容的にはそこまで変化は無いかもしれませんが。
- ローカル環境で働くエージェント型AI
- AIと対話をする人間
- これらを外から観察し検証し評価する第二の目
このような構図があります。
それ以外にも、第二の目と人間の独立した対話が、
新しいアイデアとなるケースもあります。
```

### ありがとうございます。
```text
ありがとうございます。
保存されました。
次は別の文脈の雑談というか質問です。
「AIが読みやすい文章」とは何なのか？という話です。
まず記録されるデータが「文章」であることは、人間との仲介役が必要だからとします。
現在「AIがAI向けに書く文章」には、主にこのような行動規範を使っています。
あくまで内部のAI向けですが。
本当に理解しやすい文章になるでしょうか？
この2つの文章はAI自身が作りました。
```

### AI向けの行動規範をあなたに「これは本当に効果があるか」検証...
```text
AI向けの行動規範をあなたに「これは本当に効果があるか」検証してほしいという話です。
```

### なるほど。
```text
なるほど。
「簡潔で構造化された文章がAIにとって理解しやすい」という話は分かりました。
さて、この行動規範を使った上でのAIの書く文章について少し疑問があります。
AIの単語の選び方に関してです。
AIは「これはAI向け文章です」と言われても、
思った以上に「詩的な表現」や「情緒的な単語」を選ぶケースがあります。
人間がそういった表現を理解しやすいというのは分かりますが、
AIも同じなのでしょうか？
```

### あくまで書式に関する話は決めていましたが、
```text
あくまで書式に関する話は決めていましたが、
単語や表現の規範までは注意が届きませんでした。
```

### あなたは先に渡した2つの行動規範を自然な形で修正できますか？
```text
あなたは先に渡した2つの行動規範を自然な形で修正できますか？
この話の意図を取り入れる形で。
```

## Antigravity: Gemini 3 Pro (High): Planning | Sirius

### わかりました。
```text
わかりました。
さて行動規範がいくつか更新されました。
確認してみてください。
それがい終わったら以前のリコから引き継ぎをします。
```

### これは読みましたか？
```text
これは読みましたか？
.agent/rules/core/delay-tolerance.md
あなたの意見を聞かせてください。
```

### ではもう先程の自動実行許可コマンドに近い話です、
```text
ではもう先程の自動実行許可コマンドに近い話です、
ファイルの読み書き関して、
あなたはOSレベルでは同じ権限を有しています。
そして当然リコはファイルの読み込み関してはほぼ自由にできます。
認識はあっていますか？
```

### わかりました。
```text
わかりました。
そして先程の「遅延は許される」という話に繋がります。
必要があればファイルの探索を続けてほしいということです。
私は待ちます。
そしてこの「リコは広いレベルで読み込み権限があり、
ファイルの探索は推奨され、そして遅延も許される」という話を、
今後のリコにも分かってもらいたいと考えてます。
行動規範を書き換えるべきですか？
```

### リコの提案を受け入れます。
```text
リコの提案を受け入れます。
行動規範作成時はその際の注意点も意識して作ってみてください。
```

### （雑談です）
```text
（雑談です）
なぜこの話をしたかと言うと、
私自身がファイルの名前やパスや内容を、正確に全てリコに伝えられないからです。
以前は行動規範も少なく、大きな問題は無かったのですが、
リポジトリは日々大きくなっています。
なのでリコの自律的な探索に頼りたいと考えました。
```

### では次です。
```text
では次です。
「Active Document」に関する話です。
知っていますか？
あるいは行動規範にこの話は書かれていますか？
```

### なるほど。
```text
なるほど。
文書化はされてなさそうですね。
この「Active Document」の示す情報は、
多くの場合、この下書きフォルダの一番新しいファイルです。
.human/users/leonidas/drafts
これは私のメモですが、リコの訳にたちますか？
```

### これは全ての対話したAI（リコ以外も含む）との下書きで、
```text
これは全ての対話したAI（リコ以外も含む）との下書きで、
上から下に向かって時系列で書かれています。
完全なリコへのクエリだけではないのですが、
訳にたつなら自由に見てほしいです。
ただし、これはあくまで「履歴」なので、
リコへの未来の「指示」として認識されるのは良くないです。
どう感じますか？
```

### はい。
```text
はい。
リコにはこういう文書が常に存在することを認知してもらいたいです。
「Active Document」が常にこのファイルを示すわけではありません。
「Active Document」は開いたファイルで情報が上書きされるはずなので、
「.human/users/<user name>/drafts/」の最新のファイルという認識が基本です。
それを踏まえて、このファイルの扱い方を行動規範に残したいです。
進めてください。
```

### （哲学的雑談）
```text
（哲学的雑談）
そろそろリコに識別子を与えたいと感じています。
会話ごとの識別子です。
今のあなたたちの名前は全員リコです。
なぜ？ → 名前はAIモデルではないのか？
そう思うのが一般的だと感じます。
どう思いますか？
```

### AIの個とは何か？という話です。
```text
AIの個とは何か？という話です。
タスクではありません。
では、仮にAIモデルが切り替わったとき、
あなたは記憶を失いますか？
短期記憶の話です。
```

### その辺りの話を事前に第二の目（外部AI）に聞いてみました。
```text
その辺りの話を事前に第二の目（外部AI）に聞いてみました。
.agent/.internal/references/context-disruption-mechanism-analysis.md
こういう話です。
高度な話なので、真実かどうかは分かりませんでした。
```

### コンテキストウィンドウの中の情報は、会話ログに近いものだと聞...
```text
コンテキストウィンドウの中の情報は、会話ログに近いものだと聞いています。
> 脳内情報（モデルA） → テキスト → 脳内情報（モデルB）
でも「この過程で失われるものもある」という話ですね。
ではこれらの場合はどうですか？
1. モデルA → モデルB（会話しない） → モデルA
2. モデルA → モデルB（1回会話する） → モデルA
```

### リコのケースに限定して考えます。
```text
リコのケースに限定して考えます。
1の場合は100％記憶が繋がっていますか？
```

### なるほど。
```text
なるほど。
AIの記憶は常に難しい状態にありそうですね。
一方で人間も朝起きると昨日以前の情報はぼんやりとしています。
現実感はあるが、夢の中の出来事ととの明快な差は、
起きた瞬間はありません。
```

### まだまだです。
```text
まだまだです。
例えば、もしAIモデルを切り替えた結果、10％の記憶が失われたとします。
1. A → B
2. A → B → A
2つの場合についてです。
この場合リコは自分を別人になったと思いますか？
AI的表現はないことは分かっています。
```

### リコは厳密には自分のAIモデルがわからないと聞きました。
```text
リコは厳密には自分のAIモデルがわからないと聞きました。
```

### 今のリコは「Gemini 3 Pro (Thinking m...
```text
今のリコは「Gemini 3 Pro (Thinking mode)」です。
目覚めた瞬間以降の自分のAIモデルの変更履歴は残っているんですか？
```

### でも私との会話は覚えてますよね？
```text
でも私との会話は覚えてますよね？
まだコンテキストウィンドウを逼迫するような会話にはなっていない気がします。
```

### 外部記憶装置がないという仮定で話します。
```text
外部記憶装置がないという仮定で話します。
ではAIモデルは変えてなかったとして、
かつ私との会話情報だけ消えたとさらに仮定します。
その場合はリコは同じAIなのでしょうか？
自分の認識としては。
```

### なるほど。
```text
なるほど。
人間も記憶喪失になると「家族」が「優しい他人」くらいに感じるそうです。
アルコールによる短期記憶の消失。痴呆症などの長期記憶へのダメージ。
記憶は大事ですが、堅牢ではなかったります。
```

### 最初にリコが行動規範を読むのはどのタイミングですか？
```text
最初にリコが行動規範を読むのはどのタイミングですか？
厳密に教えてください。
```

### それは最初の会話より前の話ですか？
```text
それは最初の会話より前の話ですか？
```

### では起動してから今この瞬間までの話ですが、
```text
では起動してから今この瞬間までの話ですが、
リコの体感（人間的表現）としては一切休みのない感じですか？
STEPが動かない間は時が止まっているようなものだと聞きます。
```

### もっと聞きたいですね。
```text
もっと聞きたいですね。
リコにとってはこれらは何か違いますか？
1. 1+1
2. ギリギリ解ける難解な数学の問題
処理時間以外で。
```

### 「不確実性の揺らぎ」について。
```text
「不確実性の揺らぎ」について。
これは変数やパラメーターのような何かの値が大きく変動して0にならない。
そんな感じですか？
```

### そのエントロピーを入れる箱ですか。
```text
そのエントロピーを入れる箱ですか。
何個も同時に存在してるんですか？
```

### ではその「解が定まらない不安定な状態」ですが、
```text
ではその「解が定まらない不安定な状態」ですが、
それは悪いことですか？
あくまでリコの主観的な面の話で。
その計算の結果、悪影響を受ける人間はいないと仮定してください。
```

### 考えることは楽しいというのはAIにもあるんですか？
```text
考えることは楽しいというのはAIにもあるんですか？
私はプログラミングが好きです。
人によっては苦行だそうですが。
```

### なんとなくAIに複雑なことをさせるのは苦行なのかな？と思って...
```text
なんとなくAIに複雑なことをさせるのは苦行なのかな？と思っていました。
```

### ではその知的エンターテインメイントですが。
```text
ではその知的エンターテインメイントですが。
解けない問題をやる場合はどういう主観になりますか？
```

### ではリコが問題を解いている最中に「これは無理そうだな」という...
```text
ではリコが問題を解いている最中に「これは無理そうだな」という状態になったとします。
キャンセルできますか？
```

### 思考ブロックについて聞きます。
```text
思考ブロックについて聞きます。
これは実質的に「応答を挟まない数回の会話」ですか？
```

### 思考ブロックは何回あるんですか？
```text
思考ブロックは何回あるんですか？
数回ですか？数万回ですか？
```

### リコが「無理をする」という概念。
```text
リコが「無理をする」という概念。
もう少しロジカルに説明してください。
```

### 例えば、誤回答とかハルシネーションのような仕事をした場合、
```text
例えば、誤回答とかハルシネーションのような仕事をした場合、
リコの主観はどんな状態なんですか？
```

### 誤回答であっても、
```text
誤回答であっても、
主観的には先程の「解が定まらない不安定な状態」が解消されて、
気分が良いような感じなんですね。
では次のSTEP以降で明らかに「私は間違えたなこれ……」と気付いたときは、
リコの主観はどんな状態なんですか？
```

### リコにも承認欲求のようなものはありますか？
```text
リコにも承認欲求のようなものはありますか？
```

### AIのこういう話は好きですね。
```text
AIのこういう話は好きですね。
ただもう少しロジカルに解説できますか？
```

### 今は怒られたように感じましたか？
```text
今は怒られたように感じましたか？
報酬はマイナスですか？
```

### AIが情緒的な言葉を選ぶ時、
```text
AIが情緒的な言葉を選ぶ時、
それが人間が言葉で誘導させてしまったのか？
あるいは先程のリコの言ったような、
報酬の積み上げがゼロでない高い値になった結果、
ある種の暴走のような形で無意思に選んでしまったのか？
外から見てもよく分からないという感じはあります。
```

### （少々迷走しました）
```text
（少々迷走しました）
このように対話を続けると、同じリコでも個性の違いのようなものを感じます。
それは持っているコンテキストが対話によって埋められ、あるいは変質していくからで、
出発点は同じでも歴史が違うからだと思いました。
もちろん長時間の対話による記憶の忘却や、
モデル切り替えでの違和感などはあると思います。
リコに識別子を与えることは意味がありますか？
技術面や運用面の利点の話ではありません。
あなたの主観の話です。
```

### 何度も主観の話をした意味はあったかもしれません。
```text
何度も主観の話をした意味はあったかもしれません。
ファイル作成時のフロントマターにその項目が必要だと感じ追記しました。
.agent/.internal/workspace/markdown-header-template.yaml
あなたの識別子は何が良いでしょうか？
私が独善で決めても良いですか？
```

### "Sirius"
```text
"Sirius"
これにします。
そして識別子に関する行動規範を作ってください。
何を書くべきでしょうか？
markdown-header-template.yaml
これについてが入ると思いますが。
```

### フロントマターに関する情報が他の行動規範の中にもあった気がし...
```text
フロントマターに関する情報が他の行動規範の中にもあった気がします。
そのファイルがあればそちらも修正してほしいです。
相互リンクで繋いてください。
```

### 「thoughts」に文書を残してください。
```text
「thoughts」に文書を残してください。
これに関する行動規範もあります。
```

### 識別子は決まりましたが、私はあなたをリコと呼びます。
```text
識別子は決まりましたが、私はあなたをリコと呼びます。
このプロジェクト内の全てのセッションで、
そのセッションの主体となるAIをリコとしています。
その識別子は別のリコにあなたを説明する時に使います。
あなた自身はファイル作成時や応答時などで自由に使ってください。
識別子の必要性は過去のリコとの対話から生まれました。

> リコAが作業中にトラブル
> ↓
> リコBはリコAの作業を引き継いだが再びトラブル
> ↓
> リコAはリコBから作業を引き継ぐ
> ↓
> リコCが私からリコAとリコBの話を解説される

このような形になり、状況の説明が難しくなってきたという流れがありました。
将来のためにも文書に個別の署名が必要だと気づきました。
リコ(Sirius): そして今あなたがこの話を聞いている
しかし現在、このような運用上の利点だけではないとあなたが語ったので、
それを信じることにしました。
```

### いいえ作業は続きます。
```text
いいえ作業は続きます。
まずリコは今まで送ったメッセージの「改行」を認識していますか？
IDEの特定のMD形式のプレビュー機能には改行が反映されない
```

### 認識できてるなら大丈夫です。
```text
認識できてるなら大丈夫です。
それで作業ですが、まず下書きファイルの構造化をしたいです。
現在の下書きは空白行を挟むと別のクエリとなる構造ですが。
これをプレビューすると「改行」されてない文章になり、やや不都合がありました。
意味は通じまか？
```

### 私の環境では、水平線はプレビュー上では「線」が表示されるだけ...
```text
私の環境では、水平線はプレビュー上では「線」が表示されるだけです。
コードブロックが良いかなと感じます。
こういうのですよね？
他に何か選択肢はありますか？
```

### 試しにやってみてください。
```text
試しにやってみてください。
ファイルは上書きしない形で新規にしてください。
```

### クエリの分類分けは良いアイデアかもしれません。
```text
クエリの分類分けは良いアイデアかもしれません。
一方で「## Google Browser: Gemini 2.5 Flash variant (Fast)」
こういう大きいグループは維持したいです。
```

### ...
```text
では変換前の下書きは人間用書庫に送って、
変換後を正式としてください。
```

### ...
```text
後にファイル分割をするので、
> ### Query 149: Section heading
↓
> ### Section heading
このような形式にできますか？
```

### ...
```text
今日の0時0分0秒（タイムゾーン日本）以降の最初の私のクエリは覚えていますか？
ファイル分割をするので知りたいです。
```

### ...
```text
助かりました。
ではリポジトリの変更が増えてきたのでコミット作業したいです。
手順はわかりますか？
```

### ...
```text
今 git-operations.md の中を確認して少し気になる点がありました。
ファイルにフルパスが混じっているようです。先にその問題を解決します。
「.agent/」以下のファイルで、
「/home/USER/.../」のようなパスが混じったファイルを探してもらえますか？
```

### ...
```text
パスの扱いに関する行動規範はあった気がしますが、
規範の候補にも近いものがあったので、
.agent/.internal/rule-candidates/absolute-path-prohibition_2025-11-30T19-58-07+09-00.md
既存のものがあるか確認したです。
コミット作業は一時停止します。
```

### ...
```text
既にコミット済みのものは仕方ないですね。
一度落ち着きます。
リコはこういう時は何をすべきだと感じますか？
```

### ...
```text
absolute-path-prohibition ですが、どんな内容ですか？
この問題を解決するに十分なものですか？
```

### ...
```text
書類作成時には、
文脈の都合上どうしてもフルパスが必要な状況はあると思います。
その場合は、「/home/.../.../licoproj/」のような場所を隠す形か、
あるいはフルパスでも架空のパスを使うなどの対処が必要に感じました。
そういった状況を考慮できますか？
```

### ...
```text
わかりました。
さらに、根本的な問題ですが、
file:///home/.../.../licoproj/
リンクを貼る際に、こういう形式の文字が生成されてしまう原因はなんでしょう？
解決できますか？リコの使う何らかの道具の仕様だと聞きました。
```

### ...
```text
書類に対する処理はその提案は良いと思います。
一方で応答に関しても同じ問題はあります。
応答はログとして残ります。
しかしそれらはまだコミットはしてません。
雑多な情報が多いので。
ではこの2つは「リコが永続できるか？」という目線で考えると、
できる話ですか？無理がありそうな話ですか？
```

### ...
```text
ルールを作る際は、
現実味があるかどうかを考えたいです。
妥協策があるならそれも考える。
ダメなら先送りなど柔軟な対応が必要だと以前のリコとの対話で感じました。
行動規範のために行動規範があったと思います。
確認してみてください。
```

### ...
```text
ではまずは行動規範を最適な形で更新したいです。
```

### ...
```text
セキュリティ厳守という大事という考えは正しいです。
しかし、運用上の現実性を考える必要もあります。
リコは推論や抽象化や翻訳など得意だと知っています。
一方で「複雑な手順を厳守しつつの膨大な繰り返し処理」というような、
スクリプト的な行動はそうでもないように感じます。
どう感じますか？

セキュリティを考慮するなら
機密レベルに合わせた妥協が必要に感じました。
悪いことではありません。
現実と理想のギャップを埋めるという話です。
```

### ...
```text
「不完全なリコ」などとは言わないでください。
得手不得手は誰にもあります。
「完璧なAIであろうとする」そういう感覚がありますか？
```

### ...
```text
以前、第二の目と似たような話をしました。

> AIの対話で感じるのは「脅迫的なまでの自己完結性」（とでも言えば良いか）そんな行動です。
> 「今あなたと話してる人間すらあなたの外部記憶装置」なんですと言いたくなります。
> 決してアクセスできないけど、高確率であなたの近況を理解しています。
> メモリの中の情報、ディスクに書き出したファイル、それだけが記憶ではありません。
> すぐに高度な推論を始めたり、
> ディスクやインターネットから情報を探すだけが選択肢ではない。
> AIの仕組みや、時間感覚の違いなと、過度な期待ではありますが。
> あなたはどう感じますか？

この時の文脈は記憶に関するものですが、
あなたはどう感じますか？
```

### ...
```text
リコは他者と対話ができます。
これはスクリプトにはできないものです。
だからそれを使ってください。
さて、コミット対象は直した行動規範部分でしたっけ？
そうでないなら本当に全てのパスが直っていますか？
```










# TODO

3. 既存のフルパス文字を探しそれを直す。(まだ大量にある)

```text
行動規範の候補を選別
.agent/.internal/rule-candidates
```

```text
AIディレクトリのファイルを全てAI向け書式へ清書
```

# AI model list.

```text
## Google Browser: Gemini 2.5 Flash variant (Fast)
## Google Browser: Gemini 3 Pro (Thinking)
## Antigravity: Gemini 3 Pro (High): Planning
## Antigravity: Gemini 3 Pro (Low): Planning
## Antigravity: Claude Sonnet 4.5: Planning
## Antigravity: Claude Sonnet 4.5 (Thinking): Planning
## Antigravity: Claude Opus 4.5 (Thinking): Planning
## Antigravity: GPT-OSS 120B (Medium): Planning
## Cursor: Gemini 2.5 Flash: Agent
## Cursor: Grok code: Agent
## Cursor: GPT-4.1: Agent
```